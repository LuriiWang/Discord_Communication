### Communication on an Online Chat Platform: A  First Look at Live Chat on Discord

---

Online chat platforms emerge as an important alternative for the communication of software practitioners. Among these platforms, Discord is gaining popularity in software development with its dialogs containing valuable information to practitioners and researchers. In this paper, we perform a first comprehensive empirical study on the communication of software practitioners on Discord, with a dataset of 634,065 utterances across eight open-source software communities, as well as a manually curated dataset of 655 dialogs. Our study uncovers the communication behavior of practitioners, 16 topics they discuss, and nine interaction patterns when they communicate on Discord. Based on our findings, we provide recommendations for software practitioners and outline directions for future research.


*Package Structure*
The artifact consists of following three parts：
- Data
  
  These datasets are used for analysis in subsequent four RQs.

  - *DataZIP*：This folder contains original data extracted by DiscordChatExporter, which is stored in zip format.
  - *DataJSON*: This folder contains utterances extracted from zip files in *DataZIP*, which are stored in json format.
  - *DataTXT*: This folder contains the utterances with timestamp, username and utterance content, which are extracted from JSON files.
  - *DataDialog*: This folder contains the diloags generated by auto disentanglement and manual disentanglement, based on txt files in *DataTXT*.
  - *DataThematic*：This folder contains the manual annotation results of dialogs for their topic and interaction pattern, based on dialogs in *DataDialog*.
  - *DataAscii*: This folder stores the results of the files which have been converted into ascii format, including texts from *DataTXT* and manually disentangled dialogs from *DataDialog/Manual*.
  - *DataRQ*: This folder stores the results of each RQ.
  
- Code

  - *Preprocess*：This folder contains snippets used to preprocess the collected data.
  
  - *Disentanglement*：This folder contains snippets to generate dialogs automatically by using FF Model.

  - *ThematicAnalysis*：This folder contains codebooks for annotation of topic and interaction pattern.
  
  - *QuantitativeAnalysis*：This folder contains snippets used to generate results for 4 RQs.

  These codes are used to generate Table X in the paper.
  
- Figure

  This folder contains the pdfs for all figures in the paper. All these figures are generated by using Excel.

*Requirements*

- OS：
~~~
A Windows system; Python version 3.8.10; R version 4.2.2.
~~~

- Hardware：
~~~
X86/X64 CPU; 2GB Storage.
~~~

Note that a Linux system and NVIDIA GPU(s) with > 1G memory is needed if you want to run FF model for automatic disentanglement.

<!--Although it is recommended to run the artifact with NVIDIA GPUs for faster analysis, it is not a requirement. When there is no GPU available, the CPU will be responsible for running the artifact.-->

<--------------------------TODO--------------------->
- [ ] TODO 输入输出 解纠缠环境分离 √
- [ ] TODO RQ1-RQ4 量化分析的环境 √
- [ ] TODO：增加关于文件结构的目录 √
- [ ] TODO: 增加关于环境的 requirement 的描述 e.g., 需要下载的包已经python环境等 √
- [ ] python/R语言 中下载的包需要增加一个详细的列表吗
- [ ] TODO： test case -> raw data 人工处理和自动化处理结果之间的对比
  
<--------------------------TODO--------------------->


**Reproduce the results:**
1. Data Collection
<!-- requirement 
~~~
Windows
~~~-->
To collecet the data, we used Graphical User Interface (GUI) of the DiscordChatExporter, the detailed instructions of it can be found on its [guide section](https://github.com/Tyrrrz/DiscordChatExporter/blob/master/.docs/Getting-started.md#using-the-gui). You just need to select the community channel and type in time slot in need. Then you can get the target utterances in target format (we chose json here). 
We selected seven popular technical communities in the Discord platform and further chose one general channel for each community as bellow:

| Community  | Channel                                                                                     | Start Time | End Time  |
|------------|---------------------------------------------------------------------------------------------|------------|-----------|
| Docker     | - Community/Docker                                                                          | 2018/6/25  | 2022/3/30 |
| Redis      | - General Discussion/redis-general                                                          | 2020/9/1   | 2022/3/30 |
| TensorFlow | - Discussion/tf-general                                                                     | 2017/12/27 | 2022/3/30 |
| TypeScript | - General/ts-discussion                                                                     | 2018/11/3  | 2022/3/30 |
| VSCode     | - Visual Studio Code/vsc-support-2                                                          | 2018/7/21  | 2022/3/30 |
| Angular    | - Angular/Question1                                                                        | 2020/8/30  | 2022/3/30 |
| Android    | - beginner/help-old                                                                        | 2017/8/16  | 2022/3/30 |

The collected utterances are stored in *./data/DataZIP/** in zip format.

First, you need to decompress the zip files to extract the data.
How to: Run this command from the specified directory: *./Code/preprocess/.py*

2. Data Preprocessing
   - Preprocessing Utterances
 
     We proprecessing the collected utterances in following two stages:
     
     (i) filtered out the utterances that are generated by channel bots, or contain no text but only pictures. 
     (ii) removed the emojis in the utterances by using a Python library.

       How to: Run this command from the specified directory: ./Code/preprocess/ChangeStyle.py
       Output: The output is stored in *./Data/DataTXT/**
       
     <!--The datasets we preprocessed locate in ./Data. Each utterance consists of a timestamp, a username, and a textual message.-->
       
   - Dialog Disentanglement
     
     (i) Automatic disentanglement
     We run [FF model](https://jkk.name/irc-disentanglement/) for a large-scale dialog disentanglement automatically.
      + If you want to reproduce the result of automatic disentanglement, you can install [FF model](https://jkk.name/irc-disentanglement/) by following their instructions.
      <!--T+ How to: Run the following commands in order from the specified directory: 
        1. *./Code/Disentanglement/DatasetDealing.py*
        2. *./Code/Disentanglement/GetAscii.sh*
        3. *./Code/Disentanglement/GetDialogs.sh*
        4. *./Code/Disentanglement/OutputDealing.py*
        5. *./Code/Disentanglement/DialogFormat.sh*-->
   
      + Output: The dialogs generated by automatic disentanglement are stored in *./Data/DataDialog/Auto/**
      Specifically, dialogs in a file are separated by dotted lines.
      <!--The dialogs obtained from automatic disentanglement are stored under the folder "NAME" in txt files.--> 
     <!-- File : ./Code/disentanglement--> 

     - [ ] TODO：需要增加解纠缠的整体运行过程的描述 √
  
     (ii) Manual disentanglement
     Based on the number of dialogs per community estimated in (i), we curated a manual disentanglement sample dataset for thematic analysis.
     - Output：The dialogs generated by manual disentanglement are in *./Data/DataDialog/Maunal/**
     <!--the folder "NAME" in text files.-->

    - [ ] TODO：需要增加一个关于整体数据描述的表格 √
    - [ ] TODO: 需要确认产生统计数据的代码文件
    
After the above steps, we obtained two datasets for subsequent analyses. The details of the dataset are listed as below:

- Dataset I:  including 97,160 dialogs disentangled by FF model.

| Community   | Participants | Utterance | Dilaogs|
| ----------- | -----------  | ----------|--------|
| Android     | 7,576        |249,563    |43,068  |
| Angular     | 2,627        |106,376    |17,072  |
| Docker      | 2,191        |43,212     |6,471   |
| Redis       | 262          |1,957      |586     |
| TensorFlow  | 1,842        |62,220     |8,009   |
| TypeScript  | 2,599        |151,539    |17,860  |
| VSCode      | 2,196        |19,198     |4,094   |

- Dataset II: including 655 dialogs disentangled manually.

| Community   | Participants | Utterance |Sample Dilaogs|
| ----------- | -----------  | ----------|--------------|
| Android     | 171          |2,870      |96            |
| Angular     | 141          |3,086      |96            |
| Docker      | 124          |2,179      |95            |
| Redis       | 81           |744        |83            |
| TensorFlow  | 90           |2,712      |95            |
| TypeScript  | 119          |3,669      |96            |
| VSCode      | 124          |2,029      |94            |


       
3.Research Questions
You can generate the quantitative results in each RQs by following the instructions below：
### RQ1
   - Generate statistics for Fig.4: 
  Run script: *./Code/QuantitativeAnalysis/RQ1/Get_Longtail.py* (about 97s )
  Output: the results are stored in *./Data/DataRQ/RQ1/longtail_addinfo.csv*

   - Generate statistics for Fig.5: 
  Run script: *./Code/QuantitativeAnalysis/RQ1/Get_Hourly.py* (about 75s)
  Output: the results are stored in *./Data/DataRQ/RQ1/hourly.csv*

   - Generate statistics for Fig.6: 
  Run script: *./Code/QuantitativeAnalysis/RQ1/Get_Weekly.py*
  Output: the results are stored in *./Data/DataRQ/RQ1/weekly.csv*
  
   - Generate statistics in TABLE IV: 
  Run script to get the number of utterances and mentions: *./Code/QuantitativeAnalysis/RQ1/Get_Mentions.py*
  Output: the results are stored in *./Data/DataRQ/RQ1/mention.csv*
  
   - Get the response time of dialogs in Dataset I: 
  Run script: *./Code/QuantitativeAnalysis/RQ1/Get_Speed.py*

- [ ] TODO 输入需要对应 输出格式需要调整

### RQ2

- Generate statistics for Fig.9:
  Run script: *./Code/QuantitativeAnalysis/RQ2/Get_Duration.py*

- Generate statistics for Fig.10: 
  Run script: *./Code/QuantitativeAnalysis/RQ2/Get_Length.py*

- Get the average participants in a dialog in Dataset II:
  Run script: *./Code/QuantitativeAnalysis/RQ2/Get_Participants.py*


- [ ] 小提琴图的代码需要拆分成两个 
- [ ] 增加interaction pattern的描述和决策过程

### RQ3
- Get the similarity between questions：
  Run script: *./Code/QuantitativeAnalysis/RQ3/Get_TFIDF.py*

- [ ] 需要增加RQ2和RQ3联合分析的部分内容
- [ ] 增加topic的codebook的描述和topic相关列表

### RQ4
To generate TABLE VI and TABLE VII, run the R script *./Code/QuantitativeAnalysis/RQ4/Regression.R* you can find more details in the script.
(i) You need to download R according to the [instructions](https://cran.r-project.org/mirrors.html)
(ii) Then run the commands from the specified directory to get the results of regressions:
    *setwd(".\\Discord\\Data\\DataRQ\\RQ4")*
    *source(".\\Discord\\Code\\QuantitativeAnalysis\\RQ4\\Regression.R",echo = TRUE)*

- [ ] 将其转化为可运行的r文件 √   
   
The paper figures are in:
   - Fig 1 : ./Figure/screenshot_discord.pdf
   - Fig 2 : ./Figure/chat_log.pdf
   - Fig 3 : ./Figure/process_patterns.pdf
   - Fig 4 : ./Figure/dis_utterances.pdf
   - Fig 5 : ./Figure/hourly_dis.pdf
   - Fig 6 : ./Figure/weekly_dis.pdf
   - Fig 7 : ./Figure/dis_topics_all.pdf
   - Fig 8 : ./Figure/dis_topics_across.pdf
   - Fig 9 : ./Figure/cv_per.pdf
   - Fig 10 : ./Figure/inter_patterns.pdf
   - Fig 11 : ./Figure/dis_patterns.pdf
